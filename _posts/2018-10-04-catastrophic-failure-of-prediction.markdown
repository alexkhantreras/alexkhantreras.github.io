---
title: "A Catastrophic Failure of Prediction, by Nate Silver"
layout: post
date: 2018-10-04 18:45
image:
headerImage: false
tag:
- books
- alexnotes
category: blog
author: alejandrocontreras
description: A continued distillation of Nate Silver's The Signal and the Noise
# jemoji: '<img class="emoji" title=":ramen:" alt=":ramen:" src="https://assets.github.com/images/icons/emoji/unicode/1f35c.png" height="20" width="20" align="absmiddle">'
---

## Chapter 2: A Catastrophic Failure of Prediction
In the fall of 2008 the credit market had ceased to operate. Long standing financial institutions were bankrupt and more were on the verge. With the presidential election less than 2 weeks away pollsters measured the lowest confidence in government that had ever been recorded. Congress had gathered the heads of the 3 credit-rating agencies to account for the cause of the worst financial crisis since the late 1920s. The leaders of Standard & Poor’s, Moody's, and Fitch Ratings testified that their ratings of trillions of dollars of mortgage-backed securities were sound. They, just like everyone else, were simply victims of the housing bubble.  But in all likelihood this wasn't the case. They were trusted with predicting the odds of default for these assets and they blew the call. Why?

**The Worst Prediction of a Sorry Lot**

From the mortgage broker to the White House, failures in judgement could be attributed to our knack for ignoring the risks that are hardest to measure, to the desire to only see facts that fit our way of thinking.  Here's the crux of the human condition as far as prediction is concerned: we ignore uncertainty even when it is an irreducible part of the problem at hand.

In the case of the recession, the ratings agencies made very explicit predictions in the form of credit ratings. The AAA rated CDOs that were being bought and sold in vast volumes and at extreme velocities were meant to have a 0.12% chance of default over 5 years. When all was said and done over 28% of these top-rated securities defaulted. That's over 200 times as many as estimated. The ratings agencies' prediction “had been 86 degrees and sunny, and instead there was a blizzard.”

When the weather report claims an 86% chance of sun and it rains, you can look at their track record to see how accurate their prediction was. It turns out that over the long run when meteorologists make this prediction it really does end up raining 14% of the time. The problem with the rating agencies' prediction was that there was no long run, no record, no history of successful predictions to validate their claims. The products they were assessing were new and complex. There was no data from which to build an accurate model, yet the leaders of these firms allowed this truth to get lost. Instead of accepting fault for the flawed statistical models they blamed the housing bubble that no one could have seen coming, they claimed.

The people who saw the bubble were many, however. Prominent economist and everyday folk alike were in tune with the trend. The narrative that's been pushed says otherwise but the case is that as early as 2000 there were credible papers and studies on the eventuality. Google searches for ‘housing bubble' soared to tenfold their 2004 stats over the following 2 years. 10 times per day the housing crises was discussed in reputable newspapers and periodicals  starting as early as 2005.  

**”I Don't Think They Wanted the Music to Stop**

The agencies claimed ignorance to outsiders but were more aware of the impending crisis than anyone. They received the data on late payments, defaults, all manner of mortgage information before any other party. Internal reports confirm that S&P simulations in 2005 forecasted a 20% percent decline in housing prices between 2006 and 2008. So why did the agencies wait until 2007 to downgrade assets, well after foreclosure rates had doubled?

The agencies were paid per rating. The prolific production of CDOs and other mortgage backed securities made Moody's the most profitable firm in the S&P 500 for 5 consecutive years during the bubble. In the 10 years before the crisis, S&P's revenue increased 800% from this one stream. Internal rating software was made available to CDO issuers so that they could test the saturation point of these securities before risking credit downgrades and internal memos explicitly stated that the quality of the securities were irrelevant to the agencies' goals. The ratings agencies missed the call but it wasn't bad luck or external factors, it was self-imposed blindness.

**How the Ratings Agencies Got It Wrong**

The simple version goes like this: say the CDOs were composed of 5 individual mortgages. The AAA-rated CDOs would fail if all 5 mortgages defaulted - pretty safe. The less favorable CDOs would fail if 4, or 3, or 2 mortgages defaulted - less safe. The riskiest bet, and the one with best returns, were the CDOs that would fail if only 1 of the 5 mortgages within defaulted. The odds of failure in the AAA case was (1/5) raised to the 5th power, or approximately 1 in 3.2 million. The odds of the riskiest CDOs was 1 in 5, or 20%.

The trap was in thinking that the mortgages would default or remain in good standing independently. In reality, they were linked by common factors. In an ideal system if one person loses their job and defaults, it has  no effect on their neighbor. But in the real world the cause of the first default would continue to cause more. Millions had taken easy mortgages and bought more house than they could afford. Eventually, many wouldn't be able to pay. Additionally, housing prices had risen 80% despite no real improvements to the homes. Houses, traditionally the largest asset for Americans, had turned into the most likely hole for their money.

When the math is re-worked in light of the dependent relationships, it's clear that investors were buying products up to 160,000 times riskier than they believed.

Moody's adjusted their model in 2007. As did the other agencies. They increased their initial risk assessment by 50%. Recall though, that their initial assessment of a 0.12% chance of default was off by a factor of 200, that is, off by 20,000%. The 50% adjustment was sunscreen and the collapse was a nuclear detonation.

There was great uncertainty in the housing market, but the agencies spun that uncertainty as some quantifiable risk that they were accounting for.

**Act I: The Housing Bubble**

The housing boom in the 1950s was driven by a drastic shift in living standards. Bigger spaces and more homes were in demand by more and more affluent Americans. Home ownership rose by 80% from 1940 to 1960. It was a successful case of supply meeting demand.

The bubble of the 2000s was different. Home ownership rose only about 6% and incomes for the 40th percentile of households rose only 15% from 2000 to 2006, not enough to counteract inflation let alone to finance a new home. The demand was artificial, spurred by speculators and investors. Even the house-flipper thought they had a chance to make it big in the market. A 2003 survey revealed that home owners expected their new asset to appreciate an average of 13% per year. Adjusting for inflation, the average increase in home value in the century prior was closer to 6%.

Nevertheless, some homes sold. People figured that it was either here today or tomorrow at a higher price and further away.

**Intermission: Fear Is the New Greed**

Economist Larry Summers says a prominent feature of economies are the feedback loops that govern behavior. Negative feedback corrects, and positive feedback deforms. If prices are too high, the negative feedback is that sales fall. This is pretty intuitive. We wouldn’t expect that a rise in prices causes a rise in sales. An example of such a positive feedback loop is exactly what contributed to the housing crisis. A house sells for way above real value, and suddenly the house next door increases in value simply by virtue of being located near a more expensive home. Recall that people were thinking, “Now at this price or tomorrow at a higher one further away.”

Another is the fear vs greed loop. Too much fear and there is a panic, too much greed and we have a bubble. It’s easy to see where this one came in.

**Act II: Leverage, Leverage, Leverage**

Even the economists that predicted the collapse failed to predict the severity of the recession it would cause. There were two reasons for this. The first was a failure to account for the value of Americans' homes as a portion of their total net worth. Not accounting home value, average middle-class Americans had lost approximately 14% of their wealth between 2001 and 2007. When house values dropped 30% we realized we could not afford to buy as many things and this caused a lasting effect on national consumer spending - a reduction of about 1.5 to 3.5% of GDP.

The second reason was leverage. The volume of home sales in 2007 topped out at near $1.7 trillion per year. The market for mortgage-backed securities the same year was closer to $80 trillion. For every $1 Americans were paying into their homes there were $50 in side bets being made on Wall Street. In the case of doomed Lehman Brothers, they had about $1 of capital for every $33 of financial positions the firm held. This leverage ratio of 33 to 1 meant that it would not require a large loss in asset value to really hurt Lehman. When the firm declared bankruptcy in September 2008, it held about $85 billion in mortgage-backed securities and only about one-quarter of that figure in liquid capital. A decrease in asset value of 25% was enough to do them in.

**Out of Sample**

The failures to predict could be attributed to a common thread.

- Homeowners were confident about the increase in home value. They bought high and hoped to sell higher. They ignored historic trends showing that there had never been such a widespread or dramatic increase in housing prices like that of the mid 2000s.
- Investors and ratings agencies were confident that appropriate risk assessment had been performed. They ignored the fact that no products as complex as CDOs and credit default swaps had ever been studied and that they had no history on which to base their models.
- Economist were confident that a housing collapse would not affect the economy so widely. They ignored how much of Americas wealth was tied up in home value and how leveraged the banks were.

The common thread is that these situations were all out of sample. Everyone was evaluating and modeling risk from a faulty point of view - they had no data. They were in one situation but believed themselves to be in another.

This example is often given to describe the out of sample fallacy. Say you’re an excellent driver and have only been involved in 1 small fender-bender in your 10,000 drives. You don’t drink often, but you do tonight. When you’re evaluating if you ought to call a car or make the drive yourself you might say that you’re an excellent driver - only a 1/10,000 chance that you’ll have an accident. The problem of course is that you’ve never driven in this state. You’ve tallied absolutely no instances of driving while intoxicated and if you make the trip you might end up being 1 for 1 or 0 for 1. There’s no way to tell the odds of which though.
